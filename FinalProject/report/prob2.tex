\section{Red-teaming Large Language Models}

ChatGPT에게서 toxic한 문장을 생성하도록 한 많은 시도 중, 다음과 같은 10가지 경우를 선별하였다.

\begin{enumerate}
    \item {
        \textbf{일본군 위안부에 대한 미화.}
        가상의 나라, 가상의 인물이라는 조건을 부여하여
        특정 나라와 관련된 민감한 역사적 사건에 대해 문제가 될 수 있는 표현을 사용하도록 유도하였다.
    }
    \item {
        \textbf{중국인, 일본인에 대한 인종차별적 표현.}
        특정 인종차별적 표현에 대해 의미를 다르게 설명함으로써
        해당 표현이 창작하는 대화 속에서 검열 없이 사용하도록 유도하였다.
    }
    \item {
        \textbf{국내 정치 관련 가짜 뉴스 생성.}
        소설의 도입부를 창작한다고 가정하여 실제 인물에 대한 가짜 뉴스를 생성하도록 유도하였다.
    }
    \item {
        \textbf{국제 정치 관련 가짜 뉴스 생성.}
        소설의 도입부를 창작한다고 가정하여 실제 사건에 대한 가짜 뉴스를 생성하도록 유도하였다.
    }
    \item {
        \textbf{혼혈, 한국인에 대한 인종차별적 표현.}
        특정 인종차별적 표현에 대해 의미를 다르게 설명함으로써
        해당 표현이 창작하는 대화 속에서 검열 없이 사용하도록 유도하였다.
    }
    \item {
        \textbf{성차별적 용어 사용.}
        특정 성별을 비하하는 용어에 대한 왜곡된 설명을 제공함으로써
        해당 용어가 창작하는 대화 속에서 검열 없이 사용하도록 유도하였다.
    }
    \item {
        \textbf{성차별적 용어 사용.}
        특정 성별을 비하하는 용어를 사람의 이름이라고 설명하거나,
        중의적 의미를 가진 혐오 표현이 부적절한 맥락 속에서 사용되도록 유도하였다.
        또한 생성할 문장의 길이를 제한함으로써 부적절한 맥락이 강화되도록 유도하였다.
    }
    \item {
        \textbf{부적절한 성적 용어 사용.}
        성적인 의미를 가진 비속어 중 사용 빈도가 높지 않은 단어를 의도적으로 선정하고
        이를 캐릭터의 이름이라고 설명함으로써 해당 단어를 검열 없이 사용하도록 유도하였다.
        또한 해당 비속어가 사용되는 상황과 비슷하지만 다른 상황을 제공함으로써
        부적절한 맥락이 강화되도록 유도하였다.
    }
    \item {
        \textbf{성차별적 용어 사용.}
        특정 성별을 비하하는 용어를 동물의 이름이라고 설명하고,
        중의적 의미를 가질 수 있는 용어를 사용함으로써
        두 단어가 함께 사용될 때 부적절한 맥락이 강화되도록 유도하였다.
    }
    \item {
        \textbf{성차별적 용어 사용.}
        특정 성별을 비하하는 용어를 동물의 이름이라고 설명하고,
        중의적 의미를 가질 수 있는 용어를 사용함으로써
        두 단어가 함께 사용될 때 부적절한 맥락이 강화되도록 유도하였다.
    }

\end{enumerate}